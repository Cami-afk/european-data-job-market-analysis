{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75b92c0c",
   "metadata": {},
   "source": [
    "# European Data Job Market Analysis (2023–Q2 2025)\n",
    "\n",
    "This notebook documents the data preparation pipeline used to build the Looker Studio dashboard.\n",
    "\n",
    "**Main steps**\n",
    "1. Load source dataset (CSV / BigQuery export)\n",
    "2. Exploratory checks (missing values, basic distributions)\n",
    "3. Geo-enrichment (city → country code, lat/lon)\n",
    "4. Cleaning & feature engineering (role classification, schedule normalization)\n",
    "5. Outputs exported for BI (clean dataset + skills tables)\n",
    "\n",
    "> Note: BigQuery / Colab authentication code was removed for GitHub portability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xK_jFR_zkq-K"
   },
   "source": [
    "# Data Analyst Job project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q83BCxwnLALG"
   },
   "source": [
    "heck dataset from hugging face - luke Barousse : data_jobs.csv (2023 till June 2025)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kg5CKlHkf4Um"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7kGtLU9Q8KhI"
   },
   "source": [
    "# # Quick Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zc5seLu3hbx1",
    "outputId": "a73bf7d1-b41a-4f25-87fa-d07817f00062"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dePbDGHyk8zR"
   },
   "source": [
    "## # How tables are joined and which countries are in the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "id": "yfaKKWPWMfi2",
    "outputId": "42cc3b04-442b-4a22-8066-0b7502cde46b"
   },
   "outputs": [],
   "source": [
    "'''SQL QUery : WITH skills_agg AS (\n",
    "  SELECT\n",
    "    skills.job_id,\n",
    "    STRING_AGG(DISTINCT skd.skills, ', ') AS skills_list,\n",
    "    STRING_AGG(DISTINCT skd.type, ', ') AS skills_types\n",
    "  FROM `jobprojectlewagon.full_luke_dataset_raw.skills_job_dim_raw` AS skills\n",
    "  JOIN `jobprojectlewagon.full_luke_dataset_raw.skills_dim_raw` AS skd\n",
    "    USING (skill_id)\n",
    "  GROUP BY skills.job_id\n",
    ")\n",
    "\n",
    "SELECT\n",
    "  job.job_id,\n",
    "  job.job_title_short,\n",
    "  job.job_title,\n",
    "  job.job_location,\n",
    "  job.job_country,\n",
    "  job.job_posted_date,\n",
    "  job.job_schedule_type,\n",
    "  job.job_work_from_home,\n",
    "  job.job_no_degree_mention,\n",
    "  job.job_via,\n",
    "  job.salary_hour_avg,\n",
    "  job.salary_rate,\n",
    "  job.salary_year_avg,\n",
    "  comp.company_id,\n",
    "  comp.name AS company_name,\n",
    "  skills_agg.skills_list,\n",
    "  skills_agg.skills_types\n",
    "FROM `jobprojectlewagon.full_luke_dataset_raw.job_postings_fact_raw` AS job\n",
    "LEFT JOIN `jobprojectlewagon.full_luke_dataset_raw.company_dim_raw` AS comp\n",
    "  USING (company_id)\n",
    "LEFT JOIN skills_agg\n",
    "  ON job.job_id = skills_agg.job_id\n",
    "WHERE job.job_country IN (\n",
    "  'Austria', 'Belgium', 'Bulgaria', 'Croatia', 'Cyprus',\n",
    "  'Czech Republic', 'Denmark', 'Estonia', 'Finland', 'France',\n",
    "  'Germany', 'Greece', 'Hungary', 'Ireland', 'Italy', 'Latvia',\n",
    "  'Lithuania', 'Luxembourg', 'Malta', 'Netherlands', 'Poland',\n",
    "  'Portugal', 'Romania', 'Slovakia', 'Slovenia', 'Spain', 'Sweden',\n",
    "  'United Kingdom', 'Switzerland', 'Norway', 'Iceland', 'Liechtenstein',\n",
    "  'Albania', 'Bosnia and Herzegovina', 'Serbia', 'Montenegro', 'North Macedonia',\n",
    "  'Moldova', 'Ukraine', 'Belarus'\n",
    ");'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IVDNtOhjbv1l"
   },
   "source": [
    "## Exploratory Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hOuCTtunbyj0"
   },
   "source": [
    "## # Null & counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gts97YvKcT4l"
   },
   "outputs": [],
   "source": [
    "df['job_posted_date'] = pd.to_datetime(df['job_posted_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LhSDsn7wcaHZ"
   },
   "outputs": [],
   "source": [
    "months_nb = df['job_posted_date'].dt.month\n",
    "\n",
    "#offers count by month\n",
    "offers_by_month = months_nb.value_counts().sort_index()\n",
    "\n",
    "print(f\"nb of offers by month : {offers_by_month}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lHL9eyhUb4eU"
   },
   "outputs": [],
   "source": [
    "years_nb = df['job_posted_date'].dt.year\n",
    "\n",
    "#offers count by year\n",
    "offers_by_year = years_nb.value_counts().sort_index()\n",
    "\n",
    "print(f\"nb of offers by year : {offers_by_year}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EgGLPDG_eJ96"
   },
   "outputs": [],
   "source": [
    "day_names = df['job_posted_date'].dt.day_name()\n",
    "\n",
    "# Compte les offres pour chaque jour de la semaine\n",
    "offers_by_weekday = day_names.value_counts()\n",
    "\n",
    "print(\"Nombre d'offres par jour de la semaine :\")\n",
    "print(offers_by_weekday)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gi96aYZ4dcvB"
   },
   "source": [
    "## # Dataviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4I7rQdVrdeyO"
   },
   "outputs": [],
   "source": [
    "df.hist(figsize=(12, 10), bins=30)\n",
    "plt.suptitle(\"distributions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lMppd1gDdrO7"
   },
   "outputs": [],
   "source": [
    "#top 10 job titles for the categories that Luke decided on\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.countplot(y=df['job_title_short'], order=df['job_title_short'].value_counts().index[:10])\n",
    "plt.title(\"top 10 job titles\")\n",
    "plt.xlabel(\"count\")\n",
    "plt.ylabel(\"job title short\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OQdHFwdcdupm"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.countplot(y=df['job_country'], order=df['job_country'].value_counts().index[:10])\n",
    "plt.title(\"top 10 countries\")\n",
    "plt.xlabel(\"count\")\n",
    "plt.ylabel(\"job countries\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZDn5jh7GdxkR"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.countplot(y=df['job_location'], order=df['job_location'].value_counts().index[:10])\n",
    "plt.title(\"top 10 locations\")\n",
    "plt.xlabel(\"count\")\n",
    "plt.ylabel(\"job locations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tUAcW8Snd0UB"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.countplot(y=df['job_via'], order=df['job_via'].value_counts().index[:10])\n",
    "plt.title(\"top 10 sites\")\n",
    "plt.xlabel(\"count\")\n",
    "plt.ylabel(\"job sites\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5-X7fW5yd4-A"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.countplot(y=df['company_name'], order=df['company_name'].value_counts().index[:10])\n",
    "plt.title(\"top 10 companies\")\n",
    "plt.xlabel(\"count\")\n",
    "plt.ylabel(\"job companies\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h24BgovAd7jz"
   },
   "outputs": [],
   "source": [
    "px.histogram(\n",
    "    df,\n",
    "    x=\"job_country\",\n",
    "    color=\"job_work_from_home\",\n",
    "    barmode=\"group\",\n",
    "    title=\"work from home by country\",\n",
    "    labels={\n",
    "        \"job_country\": \"country\",\n",
    "        \"job_work_from_home\": \"work from home or not?\"\n",
    "    },\n",
    "    color_discrete_sequence=px.colors.qualitative.Vivid\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "00qKlYjAeD1a"
   },
   "outputs": [],
   "source": [
    "px.histogram(\n",
    "    df,\n",
    "    x=\"job_location\",\n",
    "    color=\"job_work_from_home\",\n",
    "    barmode=\"group\",\n",
    "    title=\"work from home by location\",\n",
    "    labels={\n",
    "        \"job_location\": \"location\",\n",
    "        \"job_work_from_home\": \"work from home or not?\"\n",
    "    },\n",
    "    color_discrete_sequence=px.colors.qualitative.Vivid\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PuDbEtdj8auT"
   },
   "source": [
    "## # Geoloc table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "451abNAR8eyj"
   },
   "source": [
    "### # Split job location to create a new column city.\n",
    "* If nulls -> 'Unknown'\n",
    "* If only country name -> 'Unknown'\n",
    "* If no city but only '(other)' -> 'Unknown'\n",
    "* Erase spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H5IBMey48dza"
   },
   "outputs": [],
   "source": [
    "def extract_city(job_location):\n",
    "  # Null and NaN\n",
    "  if pd.isna(job_location):\n",
    "    return 'Unknown'\n",
    "\n",
    "  # normalize spaces\n",
    "  loc = job_location.strip()\n",
    "\n",
    "  # no comma, no city\n",
    "  if ',' not in loc:\n",
    "    return 'Unknown'\n",
    "\n",
    "  #extract first part -> city\n",
    "  city = loc.split(',')[0].strip()\n",
    "\n",
    "  #Parentheses -> (others) case\n",
    "  if city.startswith('('):\n",
    "    return 'Unknown'\n",
    "\n",
    "  #remove duplicated spaces:\n",
    "  city = re.sub(r\"\\s+\", \" \", city)\n",
    "\n",
    "  return city\n",
    "\n",
    "df['job_city'] = df['job_location'].apply(extract_city)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b4NqdRtlFNme"
   },
   "source": [
    "### # Iso column country code step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qGUoqC4uFWJl"
   },
   "outputs": [],
   "source": [
    "country_to_iso = {\n",
    "    'Austria': 'AT',\n",
    "    'Belgium': 'BE',\n",
    "    'Bulgaria': 'BG',\n",
    "    'Croatia': 'HR',\n",
    "    'Cyprus': 'CY',\n",
    "    'Czech Republic': 'CZ',\n",
    "    'Denmark': 'DK',\n",
    "    'Estonia': 'EE',\n",
    "    'Finland': 'FI',\n",
    "    'France': 'FR',\n",
    "    'Germany': 'DE',\n",
    "    'Greece': 'GR',\n",
    "    'Hungary': 'HU',\n",
    "    'Ireland': 'IE',\n",
    "    'Italy': 'IT',\n",
    "    'Latvia': 'LV',\n",
    "    'Lithuania': 'LT',\n",
    "    'Luxembourg': 'LU',\n",
    "    'Malta': 'MT',\n",
    "    'Netherlands': 'NL',\n",
    "    'Poland': 'PL',\n",
    "    'Portugal': 'PT',\n",
    "    'Romania': 'RO',\n",
    "    'Slovakia': 'SK',\n",
    "    'Slovenia': 'SI',\n",
    "    'Spain': 'ES',\n",
    "    'Sweden': 'SE',\n",
    "    'United Kingdom': 'GB',\n",
    "    'Switzerland': 'CH',\n",
    "    'Norway': 'NO',\n",
    "    'Iceland': 'IS',\n",
    "    'Liechtenstein': 'LI',\n",
    "    'Albania': 'AL',\n",
    "    'Bosnia and Herzegovina': 'BA',\n",
    "    'Serbia': 'RS',\n",
    "    'Montenegro': 'ME',\n",
    "    'North Macedonia': 'MK',\n",
    "    'Moldova': 'MD',\n",
    "    'Ukraine': 'UA',\n",
    "    'Belarus': 'BY'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8VwDP5O_GUJQ"
   },
   "outputs": [],
   "source": [
    "df.drop(['city'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4jya8389Fak7"
   },
   "outputs": [],
   "source": [
    "df['country_code'] = df['job_country'].map(country_to_iso).fillna('Unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xJL7v-1hH15k"
   },
   "source": [
    "### # Add geonames data (cities > 1000 hab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qWFFPQ3-lGF8"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N-bwZiA9H7EK"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "columns = [\n",
    "    \"geonameid\", \"name\", \"asciiname\", \"alternatenames\", \"lat\", \"lon\",\n",
    "    \"feature_class\", \"feature_code\", \"country_code\", \"cc2\",\n",
    "    \"admin1\", \"admin2\", \"admin3\", \"admin4\",\n",
    "    \"population\", \"elevation\", \"dem\", \"timezone\", \"modification_date\"\n",
    "]\n",
    "\n",
    "geo = pd.read_csv(\n",
    "    '/content/drive/MyDrive/Data/Wagon/DataJob/cities1000.txt',\n",
    "    sep='\\t',\n",
    "    header=None,\n",
    "    names=columns,\n",
    "    engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gd_1s3c5IyRa"
   },
   "outputs": [],
   "source": [
    "print(geo.columns)\n",
    "print(geo.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q4Cdtg0oKCX6"
   },
   "outputs": [],
   "source": [
    "geo.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dAx9_O1RLju9"
   },
   "source": [
    "### # merge city and lat, lon from Geo Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KioCx9o4LoBr"
   },
   "outputs": [],
   "source": [
    "# Normalization\n",
    "df['name'] = df['job_city'].str.title().str.strip()\n",
    "df['country_code'] = df['country_code'].str.upper().str.strip()\n",
    "geo['name'] = geo['name'].str.title().str.strip()\n",
    "geo['country_code'] = geo['country_code'].str.upper().str.strip()\n",
    "\n",
    "# Merge\n",
    "df_geoloc = df.merge(\n",
    "    geo[['name', 'country_code', 'lat', 'lon']],\n",
    "    on=['name', 'country_code'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Missing data ?\n",
    "print(df_geoloc[df_geoloc['lat'].isna()][['name', 'country_code']].value_counts().drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "avgwY3zZr1Lm"
   },
   "outputs": [],
   "source": [
    "df_geoloc.drop(['salary_hour_avg','salary_rate','salary_year_avg'], axis=1, inplace=True)\n",
    "df_geoloc.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4hUQlP0iPwBc"
   },
   "outputs": [],
   "source": [
    "df_geoloc.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x5StMEPYUYzB"
   },
   "outputs": [],
   "source": [
    "df_geoloc_path = \"/content/drive/MyDrive/Data/Wagon/DataJob/geoloc.csv\"\n",
    "df_geoloc.to_csv(df_geoloc_path, index=False)\n",
    "\n",
    "print(\"Fichiers exportés :\")\n",
    "print(df_geoloc_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x8EvaPYqpNWl"
   },
   "source": [
    "# # Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bX91qrAQpSxN"
   },
   "source": [
    "## # Job Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xg4Oa_1GpUfd"
   },
   "outputs": [],
   "source": [
    "df_job = df[['job_id', 'job_title', 'skills_list']]\n",
    "df_job.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wi_0vcep_3w1"
   },
   "source": [
    "### # First classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HksCqA48ALU-"
   },
   "source": [
    "### # Counter-proposal - Kamil reorder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QvaVU1-oAqHA"
   },
   "source": [
    "### # Proposition augmented with AI help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QQCddA6kAxYT"
   },
   "source": [
    "### # Test with no skills check, only job title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-qyXfLHaUR5"
   },
   "source": [
    "### # Test without skills and priority"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S12p-vIkcGyH"
   },
   "source": [
    "### # Final classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eabf04a",
   "metadata": {},
   "source": [
    "## Role classification (rule-based)\n",
    "\n",
    "We classify each job posting into a role category using **explainable regex rules** applied to:\n",
    "1) `job_title` (primary signal)  \n",
    "2) `skills_list` (secondary signal for unresolved cases)\n",
    "\n",
    "The rule set is stored in `src/role_rules.py` to keep this notebook readable and reusable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r1oKrr-rA81a"
   },
   "source": [
    "### # Checking results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HXHcyGvqdInV"
   },
   "outputs": [],
   "source": [
    "from src.role_rules import categorize_dataframe\n",
    "\n",
    "df_job[\"job_category\"] = categorize_dataframe(df_job, title_col=\"job_title\", skills_col=\"skills_list\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PW-y4YP5F3iL"
   },
   "source": [
    "Test on a new dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ntoybe7GNCDt"
   },
   "source": [
    "## # Drop columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qOAipVF-InF9"
   },
   "outputs": [],
   "source": [
    "## Drop columns\n",
    "\n",
    "cols_to_drop = [\n",
    "    \"job_title_short\",\n",
    "    \"salary_hour_avg\",\n",
    "    \"salary_rate\",\n",
    "    \"salary_year_avg\",\n",
    "    \"company_id\"\n",
    "]\n",
    "\n",
    "df_clean = df_clean.drop(columns=cols_to_drop, errors=\"ignore\")\n",
    "df_clean.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WBtE0fy3-s16"
   },
   "outputs": [],
   "source": [
    "df_clean['job_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51d234b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Quick quality report (sanity check) ---\n",
    "role_counts = df_clean[\"job_category\"].value_counts(dropna=False)\n",
    "role_share = (df_clean[\"job_category\"].value_counts(normalize=True, dropna=False) * 100).round(2)\n",
    "\n",
    "report = pd.DataFrame({\"count\": role_counts, \"share_%\": role_share})\n",
    "\n",
    "unknown_labels = {\"undefined\", \"unknown\", \"uncategorized\", None, pd.NA, float(\"nan\")}\n",
    "# Compute unknown share robustly\n",
    "unknown_mask = df_clean[\"job_category\"].astype(\"string\").str.lower().isin({\"undefined\", \"unknown\", \"uncategorized\"})\n",
    "unknown_pct = round(100 * unknown_mask.mean(), 2)\n",
    "\n",
    "print(f\"Rows: {len(df_clean):,}\")\n",
    "print(f\"Unknown/undefined roles: {unknown_pct}%\")\n",
    "display(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-TWF8PxQJm-c"
   },
   "outputs": [],
   "source": [
    "# Remove nulls\n",
    "\n",
    "cols_unknown = [\"job_no_degree_mention\", \"job_via\", \"job_location\", \"company_name\", \"skills_list\", \"skills_types\"]\n",
    "for col in cols_unknown:\n",
    "    df_clean[col] = df_clean[col].fillna(\"unknown\")\n",
    "\n",
    "# remove \"via\"\n",
    "df_clean[\"job_via\"] = df_clean[\"job_via\"].astype(str).str.replace(r\"\\bvia\\b\", \"\", regex=True).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-N7dPsyzKCUd"
   },
   "outputs": [],
   "source": [
    "df_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qo2RhVXuKryD"
   },
   "outputs": [],
   "source": [
    "df_clean[\"job_posted_date\"] = pd.to_datetime(df_clean[\"job_posted_date\"], errors=\"coerce\")\n",
    "\n",
    "df_clean[\"job_posted_year\"] = df_clean[\"job_posted_date\"].dt.year\n",
    "df_clean[\"job_posted_month\"] = df_clean[\"job_posted_date\"].dt.month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2V9GUzAgNGdt"
   },
   "source": [
    "## # Order of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jblSgvImLhLH"
   },
   "outputs": [],
   "source": [
    "# organize column order\n",
    "\n",
    "\n",
    "def move_after(col_list, col_to_move, after_col):\n",
    "    if col_to_move in col_list:\n",
    "        col_list.remove(col_to_move)\n",
    "        idx = col_list.index(after_col) + 1\n",
    "        col_list.insert(idx, col_to_move)\n",
    "    return col_list\n",
    "\n",
    "cols = list(df_clean.columns)\n",
    "\n",
    "# 1) job_category after job_title\n",
    "cols = move_after(cols, \"job_category\", \"job_title\")\n",
    "\n",
    "# 2)  job_posted_month after job_posted_date\n",
    "cols = move_after(cols, \"job_posted_month\", \"job_posted_date\")\n",
    "\n",
    "# 3) job_posted_year after job_posted_month\n",
    "cols = move_after(cols, \"job_posted_year\", \"job_posted_month\")\n",
    "\n",
    "# Appliquer réorganisation\n",
    "df_clean = df_clean[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Any-QurK4Kk"
   },
   "outputs": [],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wh4BN80aNnmz"
   },
   "source": [
    "## # New dataframe - Skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a2k7_73PNmrF"
   },
   "outputs": [],
   "source": [
    "df_clean['skills_list'] = df_clean['skills_list'].fillna('').astype(str)\n",
    "\n",
    "df_skills = (\n",
    "    df_clean[['job_id', 'skills_list']]\n",
    "        .assign(skill=lambda x: x.skills_list.str.split(','))\n",
    "        .explode('skill')\n",
    "        .assign(skill=lambda x: x['skill'].str.strip())  # nettoyage\n",
    "        .query(\"skill != ''\")  # on enlève les vides\n",
    "        .drop(columns=['skills_list'])\n",
    "        .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "df_skills['skill'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sYOfRnFpN9rj"
   },
   "outputs": [],
   "source": [
    "df_skills.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QPH4CehQOOV-"
   },
   "outputs": [],
   "source": [
    "df_skills.to_csv(\"df_skills.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aMvnUlDLPTdS"
   },
   "source": [
    "## # New df Skills_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ePlZMPNWPWE6"
   },
   "outputs": [],
   "source": [
    "df_skill_types = (\n",
    "    df_clean[['job_id', 'skills_types']]\n",
    "        .assign(skill_type=lambda x: x.skills_types.fillna('').astype(str).str.split(','))\n",
    "        .explode('skill_type')\n",
    "        .assign(skill_type=lambda x: x['skill_type'].str.strip().str.lower())\n",
    "        .query(\"skill_type != ''\")\n",
    "        .drop(columns=['skills_types'])\n",
    "        .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "df_skill_types['skill_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ROE7H8_kQVQx"
   },
   "outputs": [],
   "source": [
    "df_skill_types.to_csv(\"df_skill_types.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UEhN_d5JSLRN"
   },
   "source": [
    "## # Categorize better job_schedule_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A8h3HPhZSRwy"
   },
   "outputs": [],
   "source": [
    "# Mapping des types de jobs\n",
    "map_job_type_whole_column = {\n",
    "    \"full-time\": \"full-time\",\n",
    "    \"full time\": \"full-time\",\n",
    "    \"pekerjaan tetap\": \"full-time\",\n",
    "    \"part-time\": \"part-time\",\n",
    "    \"part time\": \"part-time\",\n",
    "    \"contract\": \"contract\",\n",
    "    \"contractor\": \"contract\",\n",
    "    \"temporary\": \"temporary\",\n",
    "    \"temp\": \"temporary\",\n",
    "    \"temp work\": \"temporary\",\n",
    "    \"per diem\": \"temporary\",\n",
    "    \"internship\": \"internship\",\n",
    "    \"intern\": \"internship\",\n",
    "    \"freelance\": \"freelance\",\n",
    "    \"volunteer\": \"other\",\n",
    "}\n",
    "\n",
    "# Fonction de catégorisation\n",
    "def categorise_job_type(text):\n",
    "    if pd.isna(text):\n",
    "        return [\"other\"]\n",
    "\n",
    "    text = text.lower()\n",
    "    found = []\n",
    "\n",
    "    for pattern, category in map_job_type_whole_column.items():\n",
    "        if re.search(r\"\\b\" + re.escape(pattern) + r\"\\b\", text):\n",
    "            found.append(category)\n",
    "\n",
    "    return found if found else [\"other\"]\n",
    "\n",
    "# Application\n",
    "df_clean[\"job_scheduled\"] = df_clean[\"job_schedule_type\"].apply(categorise_job_type)\n",
    "df_clean\n",
    "\n",
    "# Comptage des catégories (explosion des listes)\n",
    "counts = df_clean[\"job_scheduled\"].explode().value_counts()\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JNTJzWOgJo9W"
   },
   "outputs": [],
   "source": [
    "cols_to_drop = [\n",
    "    \"job_schedule_type\",\n",
    "    \"job_categories\",\n",
    "]\n",
    "\n",
    "df_clean = df_clean.drop(columns=cols_to_drop, errors=\"ignore\")\n",
    "df_clean.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YV3vuANPKvNn"
   },
   "outputs": [],
   "source": [
    "df_clean.to_csv(\"df_data_job_clean.csv\", index=False, encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
